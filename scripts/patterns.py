#!/usr/bin/env python3
"""
cc-insights íŒ¨í„´ ê°ì§€ ëª¨ë“ˆ
í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ íŒ¨í„´ ë¶„ì„
"""

import re
from dataclasses import dataclass
from typing import List, Tuple, Optional
from collections import Counter


@dataclass
class PatternMatch:
    """íŒ¨í„´ ë§¤ì¹­ ê²°ê³¼"""
    pattern_name: str
    prompt: str
    category: str  # vague, repetitive, inefficient
    issue: str
    suggestion: str
    confidence: float  # 0.0 - 1.0


# í•œêµ­ì–´ ëª¨í˜¸í•œ ìš”ì²­ íŒ¨í„´
KOREAN_VAGUE_PATTERNS: List[Tuple[str, str, str]] = [
    # (regex, issue, suggestion_template)
    (r'^(ì´ê±°|ì €ê±°|ê·¸ê±°|ì´ê²ƒ|ì €ê²ƒ|ê·¸ê²ƒ)\s',
     'ì§€ì‹œëŒ€ëª…ì‚¬ë¡œ ì‹œì‘',
     'ë¬´ì—‡ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•´ì£¼ì„¸ìš”'),

    (r'^(í™•ì¸|ì²´í¬|ê²€í† )(\s*(í•´ì¤˜|í•´ë´|ì¢€))?\.?$',
     'ëŒ€ìƒ ë¯¸ì§€ì •',
     'ë¬´ì—‡ì„ í™•ì¸í• ì§€ ëª…ì‹œ: "pm2 logsì—ì„œ ERROR í™•ì¸"'),

    (r'^(ã…‡ã…‡|ì‘|ë„¤|ë„µ|ì˜ˆ)\s*(í•´ì¤˜|ì§„í–‰|ë°°í¬|í•´ë´)?',
     'í™•ì¸ ì‘ë‹µë§Œ',
     'ì–´ë–¤ ì‘ì—…ì„ ì§„í–‰í• ì§€ ëª…ì‹œí•´ì£¼ì„¸ìš”'),

    (r'^ê³„ì†\s*(ì§„í–‰|í•´ì¤˜)?\.?$',
     'ì»¨í…ìŠ¤íŠ¸ ì˜ì¡´ì ',
     'ë¬´ì—‡ì„ ê³„ì†í• ì§€ ëª…ì‹œ: "í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê³„ì† ì§„í–‰"'),

    (r'^(ì»¤ë°‹|ë°°í¬|í…ŒìŠ¤íŠ¸|ë¹Œë“œ)(\s*(í•´ì¤˜|í•´ë´))?\.?$',
     'ë‹¨ì¼ í‚¤ì›Œë“œ',
     'ì˜µì…˜ì´ë‚˜ ë²”ìœ„ ëª…ì‹œ: "stagingì— ë°°í¬í•˜ê³  í—¬ìŠ¤ì²´í¬"'),

    (r'^(ë¡œê·¸|ìƒíƒœ|ì„œë²„)\s*(í™•ì¸|ì²´í¬)?\.?$',
     'ëŒ€ìƒ ë¶ˆëª…í™•',
     'ì–´ë–¤ ë¡œê·¸/ìƒíƒœì¸ì§€ ëª…ì‹œ: "pm2 logs laytonalpha --lines 100"'),

    (r'^(ê³ ì³|ìˆ˜ì •|ë³€ê²½)(\s*(í•´ì¤˜|í•´ë´))?\.?$',
     'ëŒ€ìƒê³¼ ë°©ë²• ë¯¸ì§€ì •',
     'ë¬´ì—‡ì„ ì–´ë–»ê²Œ ìˆ˜ì •í• ì§€ ëª…ì‹œ'),

    (r'^(ë‹¤ìŒ|ì´ìŠˆ|ë¬¸ì œ)\s*(í•´ê²°)?\.?$',
     'ëŒ€ìƒ ë¶ˆëª…í™•',
     'ì–´ë–¤ ì´ìŠˆì¸ì§€ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ'),

    (r'^í•¸ë“œì˜¤í”„\s*(ì‘ì„±|ì—…ë°ì´íŠ¸)?\.?$',
     'ë‚´ìš© ë¯¸ì§€ì •',
     'ì£¼ìš” ë³€ê²½ì‚¬í•­ê³¼ ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ê¶Œì¥'),

    (r'^Aë¡œ\s*ì§„í–‰\.?$',
     'ì„ íƒì§€ ì°¸ì¡°',
     'ì„ íƒ ë‚´ìš©ì„ ëª…ì‹œ: "Redis ìºì‹± ë°©ì‹ìœ¼ë¡œ ì§„í–‰"'),
]

# ì˜ì–´ ëª¨í˜¸í•œ íŒ¨í„´ (í˜¼ìš© ëŒ€ë¹„)
ENGLISH_VAGUE_PATTERNS: List[Tuple[str, str, str]] = [
    (r'^(fix|update|change)\s+(it|this|that)\.?$',
     'Vague reference',
     'Specify what to fix and how'),

    (r'^(check|verify|test)\.?$',
     'Missing target',
     'Specify what to check'),

    (r'^continue\.?$',
     'Context dependent',
     'Specify what to continue'),
]

# ë°˜ë³µ ê°€ëŠ¥í•œ ì‘ì—… íŒ¨í„´ (skill í›„ë³´)
AUTOMATION_PATTERNS: List[Tuple[str, str, str]] = [
    # (regex, skill_name, description)
    (r'(ë¡œê·¸|logs?)\s*(í™•ì¸|ì²´í¬|check)', 'log-check', 'ë¡œê·¸ í™•ì¸ ë° ì—ëŸ¬ ë¶„ì„'),
    (r'(í•¸ë“œì˜¤í”„|handoff)\s*(ì‘ì„±|ì—…ë°ì´íŠ¸|write)', 'handoff', 'í•¸ë“œì˜¤í”„ ë¬¸ì„œ ìë™ ì‘ì„±'),
    (r'(ë°°í¬|deploy)\s*(ì§„í–‰|í•˜ê³ |and)', 'deploy', 'ë°°í¬ ë° ìƒíƒœ í™•ì¸'),
    (r'(ìƒíƒœ|status)\s*(í™•ì¸|check)', 'status-check', 'í”„ë¡œì íŠ¸ ìƒíƒœ ì¢…í•© í™•ì¸'),
    (r'(í…ŒìŠ¤íŠ¸|test)\s*(ì‹¤í–‰|run)', 'run-tests', 'í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ ë¶„ì„'),
    (r'(ì»¤ë°‹|commit)', 'commit', 'ë³€ê²½ì‚¬í•­ ì»¤ë°‹'),
    (r'(ë¹Œë“œ|build)', 'build', 'í”„ë¡œì íŠ¸ ë¹Œë“œ'),
    (r'ì„œë²„\s*(ì¬ì‹œì‘|restart)', 'restart-server', 'ì„œë²„ ì¬ì‹œì‘'),
]

# ë¹„íš¨ìœ¨ íŒ¨í„´
INEFFICIENCY_PATTERNS: List[Tuple[str, str, str]] = [
    (r'^/clear\s*$',
     '/clear ì‚¬ìš©',
     '`claude --continue` ì‚¬ìš© ì‹œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€ ê°€ëŠ¥'),
]


def detect_vague_patterns(prompt: str) -> Optional[PatternMatch]:
    """ëª¨í˜¸í•œ í”„ë¡¬í”„íŠ¸ íŒ¨í„´ ê°ì§€"""
    prompt_lower = prompt.strip().lower()

    # ìŠ¬ë˜ì‹œ ì»¤ë§¨ë“œëŠ” ì œì™¸
    if prompt.startswith('/'):
        return None

    # ë„ˆë¬´ ì§§ì€ í”„ë¡¬í”„íŠ¸
    if len(prompt.strip()) <= 5:
        return PatternMatch(
            pattern_name='too_short',
            prompt=prompt,
            category='vague',
            issue='ë„ˆë¬´ ì§§ìŒ (5ì ì´í•˜)',
            suggestion='êµ¬ì²´ì ì¸ ì»¨í…ìŠ¤íŠ¸ì™€ ì›í•˜ëŠ” ê²°ê³¼ ëª…ì‹œ',
            confidence=0.9
        )

    # í•œêµ­ì–´ íŒ¨í„´ ì²´í¬
    for pattern, issue, suggestion in KOREAN_VAGUE_PATTERNS:
        if re.search(pattern, prompt, re.IGNORECASE):
            return PatternMatch(
                pattern_name=pattern[:20],
                prompt=prompt,
                category='vague',
                issue=issue,
                suggestion=suggestion,
                confidence=0.85
            )

    # ì˜ì–´ íŒ¨í„´ ì²´í¬
    for pattern, issue, suggestion in ENGLISH_VAGUE_PATTERNS:
        if re.search(pattern, prompt, re.IGNORECASE):
            return PatternMatch(
                pattern_name=pattern[:20],
                prompt=prompt,
                category='vague',
                issue=issue,
                suggestion=suggestion,
                confidence=0.80
            )

    return None


def detect_automation_candidates(prompts: List[str]) -> List[dict]:
    """ìë™í™” ê°€ëŠ¥í•œ ë°˜ë³µ íŒ¨í„´ ê°ì§€"""
    from collections import defaultdict

    pattern_matches = defaultdict(list)

    for prompt in prompts:
        prompt_lower = prompt.lower()

        for pattern, skill_name, description in AUTOMATION_PATTERNS:
            if re.search(pattern, prompt_lower, re.IGNORECASE):
                pattern_matches[skill_name].append(prompt)
                break

    # 3íšŒ ì´ìƒ ë°˜ë³µëœ ê²ƒë§Œ ì¶”ì²œ
    candidates = []
    for skill_name, matched_prompts in pattern_matches.items():
        if len(matched_prompts) >= 3:
            description = next(
                d for p, s, d in AUTOMATION_PATTERNS if s == skill_name
            )
            candidates.append({
                'skill_name': skill_name,
                'description': description,
                'count': len(matched_prompts),
                'samples': matched_prompts[:5],
                'confidence': min(0.95, 0.6 + len(matched_prompts) * 0.05)
            })

    return sorted(candidates, key=lambda x: x['count'], reverse=True)


def detect_inefficiency_patterns(prompts: List[str]) -> List[dict]:
    """ë¹„íš¨ìœ¨ íŒ¨í„´ ê°ì§€"""
    inefficiencies = []

    for pattern, issue, suggestion in INEFFICIENCY_PATTERNS:
        matches = [p for p in prompts if re.search(pattern, p, re.IGNORECASE)]
        if matches:
            inefficiencies.append({
                'pattern': issue,
                'count': len(matches),
                'suggestion': suggestion,
                'samples': matches[:3]
            })

    return inefficiencies


def calculate_prompt_quality_score(prompt: str) -> Tuple[int, List[str]]:
    """í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-10)"""
    score = 10
    issues = []

    # ê¸¸ì´ ì²´í¬
    if len(prompt) < 10:
        score -= 3
        issues.append('ë„ˆë¬´ ì§§ìŒ')
    elif len(prompt) < 20:
        score -= 1
        issues.append('ë‹¤ì†Œ ì§§ìŒ')

    # ì§€ì‹œëŒ€ëª…ì‚¬ ì‚¬ìš©
    if re.search(r'(ì´ê±°|ì €ê±°|ê·¸ê±°|ì´ê²ƒ|ì €ê²ƒ|ê·¸ê²ƒ|it|this|that)\s', prompt, re.IGNORECASE):
        score -= 2
        issues.append('ëª¨í˜¸í•œ ì§€ì‹œëŒ€ëª…ì‚¬')

    # íŒŒì¼ ê²½ë¡œ í¬í•¨ ì—¬ë¶€ (ì¢‹ì€ ì§•í›„)
    if re.search(r'[/\\][\w.-]+\.(py|js|ts|md|json|yaml|tsx|jsx)', prompt):
        score += 1

    # êµ¬ì²´ì  ëª…ë ¹ì–´ í¬í•¨ (ì¢‹ì€ ì§•í›„)
    if re.search(r'(pm2|npm|git|docker|python|node)\s+\w+', prompt):
        score += 1

    # ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨ (ì¢‹ì€ ì§•í›„)
    if re.search(r'(error|ì—ëŸ¬|ì˜¤ë¥˜|exception|failed|ì‹¤íŒ¨)', prompt, re.IGNORECASE):
        score += 0.5

    # ëª¨í˜¸í•œ ë™ì‚¬ë§Œ ì‚¬ìš©
    vague_verbs = re.search(r'^(í™•ì¸|ì²´í¬|ê³ ì³|ìˆ˜ì •|í•´ì¤˜|í•´ë´|check|fix|update)\s*$', prompt, re.IGNORECASE)
    if vague_verbs:
        score -= 3
        issues.append('ëŒ€ìƒ ì—†ëŠ” ë™ì‚¬ë§Œ ì‚¬ìš©')

    return max(0, min(10, int(score))), issues


def get_improvement_suggestion(prompt: str, project_context: Optional[str] = None) -> str:
    """í”„ë¡¬í”„íŠ¸ ê°œì„  ì œì•ˆ ìƒì„±"""
    prompt_lower = prompt.lower()

    suggestions = {
        'ë¡œê·¸': f'"pm2 logs {project_context or "<project>"} --lines 100ì—ì„œ ERROR ë ˆë²¨ ë¡œê·¸ í™•ì¸í•˜ê³  ì›ì¸ ë¶„ì„"',
        'í™•ì¸': '"<ëŒ€ìƒ> ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë¬¸ì œê°€ ìˆìœ¼ë©´ ì›ì¸ê³¼ í•´ê²°ì±… ì œì‹œ"',
        'ë°°í¬': '"staging í™˜ê²½ì— ë°°í¬í•˜ê³  í—¬ìŠ¤ì²´í¬ ê²°ê³¼ í™•ì¸"',
        'ì»¤ë°‹': '"í˜„ì¬ ë³€ê²½ì‚¬í•­ì„ ì»¤ë°‹í•˜ê³  ë©”ì‹œì§€ëŠ” <ë‚´ìš©> í¬í•¨"',
        'í…ŒìŠ¤íŠ¸': '"<ëª¨ë“ˆ> í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ì‹¤íŒ¨í•˜ë©´ ì›ì¸ ë¶„ì„"',
        'í•¸ë“œì˜¤í”„': '"ì˜¤ëŠ˜ ì‘ì—… ë‚´ìš©ê³¼ ë‹¤ìŒ ë‹¨ê³„ë¥¼ í•¸ë“œì˜¤í”„ ë¬¸ì„œì— ì •ë¦¬"',
    }

    for keyword, suggestion in suggestions.items():
        if keyword in prompt_lower:
            return suggestion

    return '"ë¬´ì—‡ì„(What), ì–´ë””ì„œ(Where), ì™œ(Why), ì–´ë–»ê²Œ(How)ë¥¼ í¬í•¨í•´ì„œ ì‘ì„±"'


def analyze_session_patterns(prompts_with_sessions: List[dict]) -> dict:
    """ì„¸ì…˜ ê´€ë¦¬ íŒ¨í„´ ë¶„ì„"""
    from collections import defaultdict

    sessions_per_project = defaultdict(set)
    clear_count = 0

    for entry in prompts_with_sessions:
        project = entry.get('project', 'unknown')
        session_id = entry.get('session_id', '')
        prompt = entry.get('prompt', '')

        if project:
            sessions_per_project[project].add(session_id)

        if prompt.strip().startswith('/clear'):
            clear_count += 1

    # ë™ì‹œ ì„¸ì…˜ì´ ë§ì€ í”„ë¡œì íŠ¸ ì°¾ê¸°
    multi_session_projects = {
        proj: len(sessions)
        for proj, sessions in sessions_per_project.items()
        if len(sessions) > 2
    }

    return {
        'multi_session_projects': multi_session_projects,
        'clear_count': clear_count,
        'total_projects': len(sessions_per_project),
        'avg_sessions_per_project': sum(len(s) for s in sessions_per_project.values()) / max(1, len(sessions_per_project))
    }


# ========== ìƒˆë¡œìš´ ë¶„ì„ í•¨ìˆ˜ë“¤ ==========

def detect_workflow_patterns(prompts: List[str]) -> List[dict]:
    """ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ê°ì§€ - ì—°ì†ì ì¸ ì‘ì—… íë¦„ íŒŒì•…"""
    workflows = []

    # ì¼ë°˜ì ì¸ ì›Œí¬í”Œë¡œìš° ì‹œí€€ìŠ¤ ì •ì˜
    WORKFLOW_SEQUENCES = [
        {
            'name': 'git-workflow',
            'description': 'Git ì‘ì—… íë¦„',
            'patterns': [r'(status|diff|add|commit|push|pull)', r'(ì»¤ë°‹|í‘¸ì‹œ|í’€|ìƒíƒœ)'],
            'steps': ['ë³€ê²½ì‚¬í•­ í™•ì¸', 'ìŠ¤í…Œì´ì§•', 'ì»¤ë°‹', 'í‘¸ì‹œ']
        },
        {
            'name': 'test-debug',
            'description': 'í…ŒìŠ¤íŠ¸ ë° ë””ë²„ê¹…',
            'patterns': [r'(test|í…ŒìŠ¤íŠ¸)', r'(error|ì—ëŸ¬|ë²„ê·¸|bug)', r'(fix|ìˆ˜ì •|ê³ ì³)'],
            'steps': ['í…ŒìŠ¤íŠ¸ ì‹¤í–‰', 'ì—ëŸ¬ í™•ì¸', 'ìˆ˜ì •']
        },
        {
            'name': 'deploy-check',
            'description': 'ë°°í¬ ë° í™•ì¸',
            'patterns': [r'(deploy|ë°°í¬)', r'(status|ìƒíƒœ|í™•ì¸|check)', r'(log|ë¡œê·¸)'],
            'steps': ['ë°°í¬', 'ìƒíƒœ í™•ì¸', 'ë¡œê·¸ í™•ì¸']
        }
    ]

    for workflow in WORKFLOW_SEQUENCES:
        matches = 0
        for pattern_group in workflow['patterns']:
            if any(re.search(pattern_group, p, re.IGNORECASE) for p in prompts):
                matches += 1

        if matches >= 2:  # ìµœì†Œ 2ê°œ íŒ¨í„´ ë§¤ì¹­
            workflows.append({
                'name': workflow['name'],
                'description': workflow['description'],
                'confidence': round(matches / len(workflow['patterns']), 2),
                'suggested_skill': f"/{workflow['name']}"
            })

    return workflows


def detect_learning_patterns(prompts: List[str]) -> dict:
    """í•™ìŠµ íŒ¨í„´ ê°ì§€ - ì‚¬ìš©ìì˜ ì§ˆë¬¸/í•™ìŠµ ìŠ¤íƒ€ì¼ ë¶„ì„"""
    learning_indicators = {
        'questions': [],  # ì§ˆë¬¸ í˜•íƒœ
        'explanations': [],  # ì„¤ëª… ìš”ì²­
        'examples': [],  # ì˜ˆì‹œ ìš”ì²­
        'debugging': []  # ë””ë²„ê¹… ì§ˆë¬¸
    }

    QUESTION_PATTERNS = [
        (r'(ì™œ|why|ì–´ë–»ê²Œ|how|ë¬´ì—‡|what|ì–¸ì œ|when)', 'questions'),
        (r'(ì„¤ëª…|explain|ì•Œë ¤ì¤˜|tell me)', 'explanations'),
        (r'(ì˜ˆì‹œ|example|ìƒ˜í”Œ|sample)', 'examples'),
        (r'(ì—ëŸ¬|error|ë²„ê·¸|bug|ì•ˆ ë˜|doesn\'t work|ì‹¤íŒ¨|fail)', 'debugging')
    ]

    for prompt in prompts:
        for pattern, category in QUESTION_PATTERNS:
            if re.search(pattern, prompt, re.IGNORECASE):
                learning_indicators[category].append(prompt)
                break

    total = len(prompts)
    return {
        'question_ratio': round(len(learning_indicators['questions']) / max(1, total) * 100, 1),
        'explanation_ratio': round(len(learning_indicators['explanations']) / max(1, total) * 100, 1),
        'example_requests': len(learning_indicators['examples']),
        'debugging_questions': len(learning_indicators['debugging']),
        'learning_style': _determine_learning_style(learning_indicators, total)
    }


def _determine_learning_style(indicators: dict, total: int) -> str:
    """í•™ìŠµ ìŠ¤íƒ€ì¼ íŒë‹¨"""
    question_ratio = len(indicators['questions']) / max(1, total)
    example_ratio = len(indicators['examples']) / max(1, total)
    debug_ratio = len(indicators['debugging']) / max(1, total)

    if debug_ratio > 0.3:
        return "ğŸ”§ ì‹¤ìŠµí˜• (ì§ì ‘ í•´ë³´ë©´ì„œ ë°°ì›€)"
    elif question_ratio > 0.2:
        return "ğŸ¤” íƒêµ¬í˜• (ì´ìœ ì™€ ì›ë¦¬ ì¤‘ì‹œ)"
    elif example_ratio > 0.1:
        return "ğŸ“– ì˜ˆì‹œí˜• (êµ¬ì²´ì  ì˜ˆì‹œë¡œ ì´í•´)"
    else:
        return "âš¡ ì‹¤í–‰í˜• (ë°”ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ í™•ì¸)"


def calculate_efficiency_score(prompts: List[str], sessions: dict) -> dict:
    """íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°"""
    score = 100
    issues = []

    # 1. /clear ê³¼ë‹¤ ì‚¬ìš© (-5ì ì”©)
    clear_count = sum(1 for p in prompts if p.strip() == '/clear')
    clear_penalty = min(20, clear_count * 5)
    if clear_penalty > 0:
        score -= clear_penalty
        issues.append(f"/clear {clear_count}íšŒ ì‚¬ìš©")

    # 2. ë„ˆë¬´ ì§§ì€ í”„ë¡¬í”„íŠ¸ ë¹„ìœ¨ (-ìµœëŒ€ 15ì )
    short_prompts = sum(1 for p in prompts if len(p) < 15 and not p.startswith('/'))
    short_ratio = short_prompts / max(1, len(prompts))
    if short_ratio > 0.3:
        penalty = min(15, int(short_ratio * 30))
        score -= penalty
        issues.append(f"ì§§ì€ í”„ë¡¬í”„íŠ¸ {round(short_ratio * 100)}%")

    # 3. ë™ì‹œ ì„¸ì…˜ ê³¼ë‹¤ (-ìµœëŒ€ 10ì )
    if len(sessions) > 5:
        penalty = min(10, (len(sessions) - 5) * 2)
        score -= penalty
        issues.append(f"ë™ì‹œ ì„¸ì…˜ {len(sessions)}ê°œ")

    # 4. ëª¨í˜¸í•œ í”„ë¡¬í”„íŠ¸ ë¹„ìœ¨ (-ìµœëŒ€ 15ì )
    vague_count = sum(1 for p in prompts if detect_vague_patterns(p) is not None)
    vague_ratio = vague_count / max(1, len(prompts))
    if vague_ratio > 0.2:
        penalty = min(15, int(vague_ratio * 40))
        score -= penalty
        issues.append(f"ëª¨í˜¸í•œ í”„ë¡¬í”„íŠ¸ {round(vague_ratio * 100)}%")

    # ë“±ê¸‰ ê³„ì‚°
    if score >= 90:
        grade = "S"
    elif score >= 80:
        grade = "A"
    elif score >= 70:
        grade = "B"
    elif score >= 60:
        grade = "C"
    else:
        grade = "D"

    return {
        'score': max(0, score),
        'grade': grade,
        'issues': issues,
        'recommendations': _get_efficiency_recommendations(issues)
    }


def _get_efficiency_recommendations(issues: List[str]) -> List[str]:
    """íš¨ìœ¨ì„± ê°œì„  ê¶Œì¥ì‚¬í•­"""
    recommendations = []

    for issue in issues:
        if '/clear' in issue:
            recommendations.append("â†’ `claude --continue`ë¡œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€")
        elif 'ì§§ì€ í”„ë¡¬í”„íŠ¸' in issue:
            recommendations.append("â†’ í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ì™€ ê¸°ëŒ€ ê²°ê³¼ ì¶”ê°€")
        elif 'ë™ì‹œ ì„¸ì…˜' in issue:
            recommendations.append("â†’ `/rename`ìœ¼ë¡œ ì„¸ì…˜ ì •ë¦¬")
        elif 'ëª¨í˜¸í•œ' in issue:
            recommendations.append("â†’ ì§€ì‹œëŒ€ëª…ì‚¬ ëŒ€ì‹  êµ¬ì²´ì  ëŒ€ìƒ ëª…ì‹œ")

    return recommendations


# ì¶”ê°€ íŒ¨í„´ ì •ì˜
COMPLEXITY_PATTERNS = [
    (r'(ë³µì¡í•œ|complex|advanced|ê³ ê¸‰)', 'high'),
    (r'(ê°„ë‹¨í•œ|simple|basic|ê¸°ë³¸)', 'low'),
    (r'(ì¤‘ê°„|moderate|ì¼ë°˜)', 'medium')
]

DOMAIN_PATTERNS = [
    (r'(api|endpoint|rest|graphql)', 'backend'),
    (r'(component|ui|css|style|design)', 'frontend'),
    (r'(db|database|query|sql)', 'database'),
    (r'(deploy|ci|cd|docker|k8s)', 'devops'),
    (r'(test|spec|coverage)', 'testing')
]


def detect_domain_focus(prompts: List[str]) -> dict:
    """ì‘ì—… ë„ë©”ì¸ ë¶„ì„"""
    domain_counts = Counter()

    for prompt in prompts:
        prompt_lower = prompt.lower()
        for pattern, domain in DOMAIN_PATTERNS:
            if re.search(pattern, prompt_lower):
                domain_counts[domain] += 1
                break

    total = sum(domain_counts.values())
    return {
        'primary_domain': domain_counts.most_common(1)[0][0] if domain_counts else 'general',
        'domain_distribution': dict(domain_counts),
        'focus_ratio': round(domain_counts.most_common(1)[0][1] / max(1, total) * 100, 1) if domain_counts else 0
    }
